{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 193.0ms\n",
      "Speed: 6.0ms preprocess, 193.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 19.0ms\n",
      "Speed: 2.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 18.7ms\n",
      "Speed: 2.0ms preprocess, 18.7ms inference, 6.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 22.1ms\n",
      "Speed: 2.0ms preprocess, 22.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.3ms\n",
      "Speed: 2.0ms preprocess, 17.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.6ms\n",
      "Speed: 2.0ms preprocess, 18.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 19.0ms\n",
      "Speed: 2.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 21.0ms\n",
      "Speed: 2.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 27.0ms\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 16.0ms\n",
      "Speed: 4.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 27.0ms\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 19.0ms\n",
      "Speed: 2.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 26.5ms\n",
      "Speed: 2.0ms preprocess, 26.5ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 19.0ms\n",
      "Speed: 2.0ms preprocess, 19.0ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 21.0ms\n",
      "Speed: 2.0ms preprocess, 21.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 19.0ms\n",
      "Speed: 2.0ms preprocess, 19.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 19.0ms\n",
      "Speed: 1.0ms preprocess, 19.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 19.0ms\n",
      "Speed: 2.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 21.0ms\n",
      "Speed: 1.0ms preprocess, 21.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 19.0ms\n",
      "Speed: 3.0ms preprocess, 19.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 vehicles, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 vehicle, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 23.0ms\n",
      "Speed: 2.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "Vehicles Destroyed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import Any\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import perf_counter\n",
    "import carla\n",
    "import queue\n",
    "import random\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from deep_sort.deep_sort import DeepSort\n",
    "from deep_sort.utils.parser import get_config\n",
    "from pascal_voc_writer import Writer\n",
    "\n",
    "import concurrent.futures\n",
    "from functools import partial\n",
    "\n",
    "# Part 1\n",
    "#image size\n",
    "image_w = 256*4\n",
    "image_h = 256*3\n",
    "\n",
    "#yolo filtering\n",
    "class_id = [2, 5, 7]\n",
    "class_name = { 2: 'car', 5: 'bus' ,7: 'truck'}\n",
    "\n",
    "cfg = get_config()\n",
    "cfg.merge_from_file('deep_sort/configs/deep_sort.yaml')\n",
    "deepsort_weights = \"deep_sort/deep/checkpoint/ckpt.t7\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#deepsort parameters \n",
    "deepsort = DeepSort(\n",
    "            deepsort_weights,\n",
    "            max_age=70)\n",
    "\n",
    "#establising Carla connection\n",
    "client = carla.Client('localhost', 2000)\n",
    "world  = client.get_world()\n",
    "\n",
    "# Set up the simulator in synchronous mode\n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True \n",
    "settings.fixed_delta_seconds = 0.05\n",
    "world.apply_settings(settings)\n",
    "\n",
    "# Get the world spectator\n",
    "spectator = world.get_spectator() \n",
    "\n",
    "# Get the map spawn points\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "\n",
    "#vehicle setup\n",
    "vehicle_bp =world.get_blueprint_library().find('vehicle.lincoln.mkz_2020')\n",
    "vehicle_bp.set_attribute('role_name', 'ego')\n",
    "vehicle = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "\n",
    "#camera setip\n",
    "camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "camera_bp.set_attribute('image_size_x', f'{image_w}')\n",
    "camera_bp.set_attribute('image_size_y', f'{image_h}')\n",
    "camera_bp.set_attribute('fov', '110')\n",
    "fov = 110\n",
    "\n",
    "# attaching camera\n",
    "camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "\n",
    "#auto pilot for ego vehicle\n",
    "vehicle.set_autopilot(True)\n",
    "\n",
    "# Create a queue to store and retrieve the sensor data\n",
    "image_queue = queue.Queue()\n",
    "camera.listen(image_queue.put)\n",
    "\n",
    "# Part 2\n",
    "\n",
    "def build_projection_matrix(w, h, fov, is_behind_camera=False):\n",
    "    focal = w / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "    K = np.identity(3)\n",
    "\n",
    "    if is_behind_camera:\n",
    "        K[0, 0] = K[1, 1] = -focal\n",
    "    else:\n",
    "        K[0, 0] = K[1, 1] = focal\n",
    "    K[0, 2] = w / 2.0\n",
    "    K[1, 2] = h / 2.0\n",
    "    return K\n",
    "\n",
    "def get_image_point(loc, K, w2c):\n",
    "    # Calculate 2D projection of 3D coordinate\n",
    "\n",
    "    point = np.array([loc.x, loc.y, loc.z, 1])\n",
    "    point_camera = np.dot(w2c, point)\n",
    "    point_camera = np.array([point_camera[1], -point_camera[2], point_camera[0]]).T\n",
    "    point_img = np.dot(K, point_camera)\n",
    "    point_img[0] /= point_img[2]\n",
    "    point_img[1] /= point_img[2]\n",
    "\n",
    "    return point_img\n",
    "\n",
    "# Remember the edge pairs\n",
    "edges = [[0,1], [1,3], [3,2], [2,0], [0,4], [4,5], [5,1], [5,7], [7,6], [6,4], [6,2], [7,3]]\n",
    "\n",
    "# Get the world to camera matrix\n",
    "world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "\n",
    "# Calculate the camera projection matrix to project from 3D -> 2D\n",
    "K   = build_projection_matrix(image_w, image_h, fov)\n",
    "K_b = build_projection_matrix(image_w, image_h, fov, is_behind_camera=True)\n",
    "\n",
    "for i in range(30):\n",
    "    vehicle_bp = world.get_blueprint_library().filter('vehicle')\n",
    "\n",
    "    # Exclude bicycle\n",
    "    car_bp = [bp for bp in vehicle_bp if int(bp.get_attribute('number_of_wheels')) == 4]\n",
    "    npc = world.try_spawn_actor(random.choice(car_bp), random.choice(spawn_points))\n",
    "\n",
    "    if npc:\n",
    "        npc.set_autopilot(True)\n",
    "\n",
    "# Retrieve all these type objects \n",
    "\n",
    "car_objects = world.get_environment_objects(carla.CityObjectLabel.Car) \n",
    "truck_objects = world.get_environment_objects(carla.CityObjectLabel.Truck) \n",
    "bus_objects = world.get_environment_objects(carla.CityObjectLabel.Bus) \n",
    "env_object_ids = []\n",
    "for obj in (car_objects + truck_objects + bus_objects):\n",
    "    env_object_ids.append(obj.id)\n",
    "\n",
    "world.enable_environment_objects(env_object_ids, False)  # Disable all static vehicles\n",
    "\n",
    "edges = [[0,1], [1,3], [3,2], [2,0], [0,4], [4,5], [5,1], [5,7], [7,6], [6,4], [6,2], [7,3]]\n",
    "\n",
    "def point_in_canvas(pos, img_h, img_w):\n",
    "    \"\"\"Return true if point is in canvas\"\"\"\n",
    "    if (pos[0] >= 0) and (pos[0] < img_w) and (pos[1] >= 0) and (pos[1] < img_h):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_vanishing_point(p1, p2, p3, p4):\n",
    "\n",
    "    k1 = (p4[1] - p3[1]) / (p4[0] - p3[0])\n",
    "    k2 = (p2[1] - p1[1]) / (p2[0] - p1[0])\n",
    "\n",
    "    vp_x = (k1 * p3[0] - k2 * p1[0] + p1[1] - p3[1]) / (k1 - k2)\n",
    "    vp_y = k1 * (vp_x - p3[0]) + p3[1]\n",
    "\n",
    "    return [vp_x, vp_y]\n",
    "\n",
    "def clear():\n",
    "    \"\"\"destroy all the actors\n",
    "    \"\"\"\n",
    "    settings = world.get_settings()\n",
    "    settings.synchronous_mode = False # Disables synchronous mode\n",
    "    settings.fixed_delta_seconds = None\n",
    "    world.apply_settings(settings)\n",
    "\n",
    "    camera.stop()\n",
    "    \n",
    "    \n",
    "    #destroy all npc's\n",
    "    for npc in world.get_actors().filter('*vehicle*'):\n",
    "        if npc:\n",
    "            npc.destroy()\n",
    "\n",
    "    print(\"Vehicles Destroyed.\")\n",
    "\n",
    "vehicle.set_autopilot(True)\n",
    "edges = [[0,1], [1,3], [3,2], [2,0], [0,4], [4,5], [5,1], [5,7], [7,6], [6,4], [6,2], [7,3]]\n",
    "\n",
    "frames_count = 0\n",
    "annotations = []\n",
    "sort_final = []\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    while True:\n",
    "        try:\n",
    "            world.tick()\n",
    "    \n",
    "            # Move the spectator to the top of the vehicle \n",
    "            transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=-4,z=50)), carla.Rotation(yaw=-180, pitch=-90)) \n",
    "            spectator.set_transform(transform) \n",
    "    \n",
    "            # Retrieve and reshape the image\n",
    "            image = image_queue.get()\n",
    "            img = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))[:, :, :3]\n",
    "    \n",
    "    \n",
    "            timestamp_sec = image.timestamp \n",
    "            \n",
    "            # Get the camera matrix \n",
    "            world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "            \n",
    "            # Get the image frame from the image queue\n",
    "            frame = np.copy(img)  \n",
    "            frames_count += 1\n",
    "            ground_truth_annotations = []\n",
    "            DSort_nnotations = []\n",
    "    \n",
    "            # Perform YOLO object detection\n",
    "            model = YOLO('weights/best.pt')\n",
    "            preds = model(frame)\n",
    "    \n",
    "            bbox_xyxy = []\n",
    "            conf_score = []\n",
    "            cls_id = []\n",
    "            outputs = []\n",
    "    \n",
    "            # Iterate through the detected objects and their bounding boxes\n",
    "            for box in preds:\n",
    "                for r in box.boxes.data.tolist():\n",
    "                    x_min, y_min, x_max, y_max, conf, class_ids = r\n",
    "                    id = int(class_ids)\n",
    "                    if id in class_id:\n",
    "                        bbox_xyxy.append([int(x_min), int(y_min), int(x_max), int(y_max)])\n",
    "                        conf_score.append(conf)\n",
    "                        cls_id.append(int(id))\n",
    "                    else:\n",
    "                        continue         \n",
    "                    outputs = deepsort.update(bbox_xyxy, conf_score, frame)\n",
    "                    for output , conf , id in zip(outputs , conf_score , cls_id):\n",
    "                        DSort_nnotations.append({\n",
    "                                        \n",
    "                                        \"height\": int(output[3] - output[1]),\n",
    "                                        \"width\": int(output[2] - output[0]),\n",
    "                                        \"id\": \"vehicle\",  \n",
    "                                        \"y\": int(output[1]),\n",
    "                                        \"x\": int(output[0])\n",
    "                                    })                     \n",
    "    \n",
    "            sort_final.append({\n",
    "                                    \"timestamp\": timestamp_sec,\n",
    "                                    \"num\": image.frame,\n",
    "                                    \"class\": \"frame\",\n",
    "                                    \"hypotheses\": DSort_nnotations\n",
    "                                })\n",
    "                \n",
    "            hypo = [{\n",
    "                \"frames\": sort_final,\n",
    "                \"class\": \"video\",\n",
    "                \"filename\": \"yolo.json\"\n",
    "            }]\n",
    "    \n",
    "            for npc in world.get_actors().filter('*vehicle*'):\n",
    "    \n",
    "                # Filter out the ego vehicle\n",
    "                if npc.id != vehicle.id:\n",
    "                    bb = npc.bounding_box\n",
    "                    dist = npc.get_transform().location.distance(vehicle.get_transform().location)\n",
    "    \n",
    "                    # Filter for the vehicles within 50m\n",
    "                    if dist < 50:\n",
    "                        forward_vec = vehicle.get_transform().get_forward_vector()\n",
    "                        ray = npc.get_transform().location - vehicle.get_transform().location\n",
    "                        if forward_vec.dot(ray) > 0:\n",
    "                            verts = [v for v in bb.get_world_vertices(npc.get_transform())]\n",
    "                            points_image = []\n",
    "    \n",
    "                            for vert in verts:\n",
    "                                ray0 = vert - camera.get_transform().location\n",
    "                                cam_forward_vec = camera.get_transform().get_forward_vector()\n",
    "                                if (cam_forward_vec.dot(ray0) > 0):\n",
    "                                    p = get_image_point(vert, K, world_2_camera)\n",
    "                                else:\n",
    "                                    p = get_image_point(vert, K_b, world_2_camera)\n",
    "    \n",
    "                                points_image.append(p)\n",
    "\n",
    "                            x_min, x_max = 10000, -10000\n",
    "                            y_min, y_max = 10000, -10000\n",
    "    \n",
    "                            for edge in edges:\n",
    "                                p1 = points_image[edge[0]]\n",
    "                                p2 = points_image[edge[1]]\n",
    "    \n",
    "                                p1_in_canvas = point_in_canvas(p1, image_h, image_w)\n",
    "                                p2_in_canvas = point_in_canvas(p2, image_h, image_w)\n",
    "    \n",
    "                                # Both points are out of the canvas\n",
    "                                if not p1_in_canvas and not p2_in_canvas:\n",
    "                                    continue     \n",
    "                                # Draw 2D Bounding Boxes\n",
    "                                p1_temp, p2_temp = (p1.copy(), p2.copy())\n",
    "    \n",
    "                                # One of the point is out of the canvas\n",
    "                                if not (p1_in_canvas and p2_in_canvas):\n",
    "                                    p = [0, 0]\n",
    "    \n",
    "                                    # Find the intersection of the edge with the window border\n",
    "                                    \n",
    "                                    p_in_canvas, p_not_in_canvas = (p1, p2) if p1_in_canvas else (p2, p1)\n",
    "                                            \n",
    "                                    k = (p_not_in_canvas[1] - p_in_canvas[1]) / (p_not_in_canvas[0] - p_in_canvas[0])\n",
    "    \n",
    "                                    x = np.clip(p_not_in_canvas[0], 0, image.width)\n",
    "                                    y = k * (x - p_in_canvas[0]) + p_in_canvas[1]\n",
    "    \n",
    "                                    if y >= image.height:\n",
    "                                        p[0] = (image.height - p_in_canvas[1]) / k + p_in_canvas[0]\n",
    "                                        p[1] = image.height - 1\n",
    "                                    elif y <= 0:\n",
    "                                        p[0] = (0 - p_in_canvas[1]) / k + p_in_canvas[0]\n",
    "                                        p[1] = 0\n",
    "                                    else:\n",
    "                                        p[0] = image.width - 1 if x == image.width else 0\n",
    "                                        p[1] = y\n",
    "    \n",
    "                                    p1_temp, p2_temp = (p, p_in_canvas)\n",
    "\n",
    "                                \n",
    "                                # Find the rightmost vertex\n",
    "                                x_max = p1_temp[0] if p1_temp[0] > x_max else x_max\n",
    "                                x_max = p2_temp[0] if p2_temp[0] > x_max else x_max\n",
    "    \n",
    "                                # Find the leftmost vertex\n",
    "                                x_min = p1_temp[0] if p1_temp[0] < x_min else x_min\n",
    "                                x_min = p2_temp[0] if p2_temp[0] < x_min else x_min\n",
    "    \n",
    "                                # Find the highest vertex\n",
    "                                y_max = p1_temp[1] if p1_temp[1] > y_max else y_max\n",
    "                                y_max = p2_temp[1] if p2_temp[1] > y_max else y_max\n",
    "    \n",
    "                                # Find the lowest vertex\n",
    "                                y_min = p1_temp[1] if p1_temp[1] < y_min else y_min\n",
    "                                y_min = p2_temp[1] if p2_temp[1] < y_min else y_min\n",
    "                                \n",
    "                                '''\n",
    "                                # Update the rightmost and leftmost x-coordinates\n",
    "                                x_max = max(p1_temp[0], p2_temp[0], x_max)\n",
    "                                x_min = min(p1_temp[0], p2_temp[0], x_min)\n",
    "\n",
    "                                # Update the highest and lowest y-coordinates\n",
    "                                y_max = max(p1_temp[1], p2_temp[1], y_max)\n",
    "                                y_min = min(p1_temp[1], p2_temp[1], y_min)\n",
    "                                '''\n",
    "    \n",
    "                            # Exclude very small bounding boxes\n",
    "                            if (y_max - y_min) * (x_max - x_min) > 100 and (x_max - x_min) > 20:\n",
    "                                if point_in_canvas((x_min, y_min), image_h, image_w) and point_in_canvas((x_max, y_max), image_h, image_w):\n",
    "                                    img = np.array(img, dtype=np.uint8)\n",
    "                                    cv2.line(img, (int(x_min),int(y_min)), (int(x_max),int(y_min)), (0,0,255, 255), 1)\n",
    "                                    cv2.line(img, (int(x_min),int(y_max)), (int(x_max),int(y_max)), (0,0,255, 255), 1)\n",
    "                                    cv2.line(img, (int(x_min),int(y_min)), (int(x_min),int(y_max)), (0,0,255, 255), 1)\n",
    "                                    cv2.line(img, (int(x_max),int(y_min)), (int(x_max),int(y_max)), (0,0,255, 255), 1)\n",
    "                                    \n",
    "                                ground_truth_annotations.append({\n",
    "                                                                \"dco\": True,\n",
    "                                                                \"height\": int(y_max - y_min),\n",
    "                                                                \"width\": int(x_max - x_min),\n",
    "                                                                \"id\": \"vehicle\",  # Replace with actual class name\n",
    "                                                                \"y\": int(y_min),\n",
    "                                                                \"x\": int(x_min)\n",
    "                                                            })\n",
    "            annotations.append({\n",
    "                                    \"timestamp\": timestamp_sec,\n",
    "                                    \"num\": image.frame,\n",
    "                                    \"class\": \"frame\",\n",
    "                                    \"annotations\": ground_truth_annotations\n",
    "                                })\n",
    "                    \n",
    "            gt_output = [{\n",
    "                \"frames\": annotations,\n",
    "                \"class\": \"video\",\n",
    "                \"filename\": \"gt.json\"\n",
    "            }]\n",
    "    \n",
    "            with open('gt.json', 'w') as json_file:\n",
    "                json.dump(gt_output, json_file)\n",
    "                \n",
    "            with open('yolo.json', 'w') as json_file:\n",
    "                json.dump(hypo, json_file)\n",
    "\n",
    "            cv2.imshow('Ground Truth',img)\n",
    "            print(frames_count)\n",
    "            \n",
    "    \n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "                clear()\n",
    "                break\n",
    "    \n",
    "        except KeyboardInterrupt as e:\n",
    "            clear()\n",
    "            break\n",
    "\n",
    "camera.stop()\n",
    "camera.destroy()\n",
    "vehicle.destroy()\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
