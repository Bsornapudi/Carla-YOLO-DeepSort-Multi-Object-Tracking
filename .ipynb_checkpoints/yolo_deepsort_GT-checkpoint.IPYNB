{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in grounf truth file\n",
      "in init\n",
      "in load model\n",
      "connected to carla\n",
      "vehicle\n",
      "spawn points\n",
      "spawn vehicle\n",
      "set cam attributes\n",
      "cam settings done\n",
      "cam initilized\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "from typing import Any\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import perf_counter\n",
    "from ultralytics import YOLO\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "import carla\n",
    "import random\n",
    "import os\n",
    "from deep_sort.deep_sort import DeepSort\n",
    "from deep_sort.utils.parser import get_config\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from pascal_voc_writer import Writer\n",
    "import find_groundtruth\n",
    "import json\n",
    "\n",
    "\n",
    "YOLO_PATH = 'yolov8n.pt'\n",
    "class_id = [1, 2, 3, 5, 7]\n",
    "class_name = {1: 'bicycle' , 2: 'car', 3: 'motorcycle', 5: 'bus' ,7: 'truck'}\n",
    "\n",
    "IM_WIDTH = image_w =  256*4\n",
    "IM_HEIGHT = image_h = 256*3\n",
    "palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n",
    "\n",
    "output_path = \"output_video.mp4\"\n",
    "\n",
    "class main:\n",
    "    def __init__(self):\n",
    "        print('in init')\n",
    "        \n",
    "        self.model = self.load_model()\n",
    "        self.save_vid = True\n",
    "        self.output_path = \"output_video.mp4\"\n",
    "        self.cfg = get_config()\n",
    "        self.cfg.merge_from_file('deep_sort/configs/deep_sort.yaml')\n",
    "        self.deepsort_weights = \"deep_sort/deep/checkpoint/ckpt.t7\"\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.deepsort = DeepSort(\n",
    "            self.deepsort_weights,\n",
    "            max_age=70\n",
    "        )\n",
    "        \n",
    "    def load_model(self):\n",
    "        print('in load model')\n",
    "        model = YOLO(YOLO_PATH)\n",
    "        return model\n",
    "\n",
    "    def build_projection_matrix(self, w, h, fov, is_behind_camera=False):\n",
    "        focal = w / (2.0 * np.tan(fov * np.pi / 360.0))\n",
    "        K = np.identity(3)\n",
    "        if is_behind_camera:\n",
    "            K[0, 0] = K[1, 1] = -focal\n",
    "        else:\n",
    "            K[0, 0] = K[1, 1] = focal\n",
    "        K[0, 2] = w / 2.0\n",
    "        K[1, 2] = h / 2.0\n",
    "        return K   \n",
    "   \n",
    "    def __call__(self):\n",
    "        \n",
    "        client = carla.Client('localhost', 2000)\n",
    "        client.set_timeout(20.0)\n",
    "        world = client.get_world()\n",
    "        print('connected to carla')\n",
    "\n",
    "        bp_lib = world.get_blueprint_library()\n",
    "        vehicle_bp = bp_lib.find('vehicle.lincoln.mkz_2020')\n",
    "        print('vehicle')\n",
    "        spawn_points = world.get_map().get_spawn_points()\n",
    "        print('spawn points')\n",
    "        vehicle = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "        print('spawn vehicle')\n",
    "        \n",
    "        #print('spectator')\n",
    "        #spectator = world.get_spectator()\n",
    "        #transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=-4, z=2.5)), carla.Rotation(yaw=-180, pitch=-90))     \n",
    "        #spectator.set_transform(transform)\n",
    "\n",
    "        camera_bp = bp_lib.find('sensor.camera.rgb')\n",
    "        \n",
    "        print('set cam attributes')\n",
    "        camera_bp.set_attribute('image_size_x', f'{IM_WIDTH}')\n",
    "        camera_bp.set_attribute('image_size_y', f'{IM_HEIGHT}')\n",
    "        fov = camera_bp.set_attribute('fov', '110')\n",
    "        print('cam settings done')\n",
    "        fov = 110\n",
    "        \n",
    "        camera_init_trans = carla.Transform(carla.Location(z=2))\n",
    "        print('cam initilized')\n",
    "        camera = world.try_spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "        print('cam attached')\n",
    "        \n",
    "        image_queue = queue.Queue()\n",
    "        print('image queue')\n",
    "        camera.listen(image_queue.put)\n",
    "\n",
    "        def camera_callback(image, data_dict):\n",
    "            image_data = np.array(image.raw_data)\n",
    "            image_rgb = image_data.reshape((image.height, image.width, 4))[:, :, :3]\n",
    "            data_dict['image'] = image_rgb\n",
    "\n",
    "        camera_data = {'image': np.zeros((IM_HEIGHT, IM_WIDTH, 4))}\n",
    "        camera.listen(lambda image: camera_callback(image, camera_data))\n",
    "        \n",
    "        edges = [[0,1], [1,3], [3,2], [2,0], [0,4], [4,5], [5,1], [5,7], [7,6], [6,4], [6,2], [7,3]]\n",
    "        world_2_camera = np.array(camera.get_transform().get_inverse_matrix())\n",
    "\n",
    "        K   = self.build_projection_matrix(IM_WIDTH, IM_HEIGHT, fov)\n",
    "        K_b = self.build_projection_matrix(IM_WIDTH, IM_HEIGHT, fov, is_behind_camera=True)\n",
    "        \n",
    "        print('spawn vehicles')\n",
    "        for i in range(30):\n",
    "            vehicle_bp = bp_lib.filter('vehicle')\n",
    "            car_bp = [bp for bp in vehicle_bp if int(bp.get_attribute('number_of_wheels')) == 4]\n",
    "            npc = world.try_spawn_actor(random.choice(car_bp), random.choice(spawn_points))\n",
    "            if npc:\n",
    "                npc.set_autopilot(True)\n",
    "                \n",
    "        print('get objects filtered ')\n",
    "        car_objects = world.get_environment_objects(carla.CityObjectLabel.Car) \n",
    "        truck_objects = world.get_environment_objects(carla.CityObjectLabel.Truck) \n",
    "        bus_objects = world.get_environment_objects(carla.CityObjectLabel.Bus) \n",
    "\n",
    "        env_object_ids = []\n",
    "\n",
    "        for obj in (car_objects + truck_objects + bus_objects):\n",
    "            env_object_ids.append(obj.id)\n",
    "\n",
    "        # Disable all static vehicles\n",
    "        world.enable_environment_objects(env_object_ids, False) \n",
    "        edges = [[0,1], [1,3], [3,2], [2,0], [0,4], [4,5], [5,1], [5,7], [7,6], [6,4], [6,2], [7,3]]\n",
    "            \n",
    "        def clear():\n",
    "            camera.stop()\n",
    "            for npc in world.get_actors().filter('*vehicle*'):\n",
    "                if npc:\n",
    "                    npc.destroy()\n",
    "            print(\"Vehicles Destroyed.\")    \n",
    "            \n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        video_writer = cv2.VideoWriter(self.output_path, fourcc, 20.0, (IM_WIDTH, IM_HEIGHT))\n",
    "\n",
    "        vehicle.set_autopilot(True)\n",
    "        edges = [[0,1], [1,3], [3,2], [2,0], [0,4], [4,5], [5,1], [5,7], [7,6], [6,4], [6,2], [7,3]]\n",
    "\n",
    "        print('before while loop')\n",
    "        yolo_writer = Writer('yolo.xml', image_w, image_h)\n",
    "        gt_writer = Writer('groundtruth.xml', image_w, image_h)\n",
    "        deepsort_annotations = []\n",
    "        deepsort_final_annotations = []\n",
    "        ds_output = []\n",
    "\n",
    "        while True:\n",
    "            print('inside while loop')\n",
    "            world.tick()\n",
    "            \n",
    "            transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=-4,z=50)), carla.Rotation(yaw=-180, pitch=-90)) \n",
    "            spectator.set_transform(transform)\n",
    "            \n",
    "            frame_gt = image_queue.get()\n",
    "            img = np.reshape(np.copy(frame_gt.raw_data), (frame_gt.height, frame_gt.width, 4))\n",
    "            \n",
    "            gt_file = 'output/%06d' % frame_gt.frame\n",
    "            frame_gt.save_to_disk(gt_file + '.png')\n",
    "            gt_writer = Writer(gt_file + '.png', IM_WIDTH, IM_HEIGHT)\n",
    "            timestamp_sec = frame_gt.timestamp\n",
    "\n",
    "            print('calling ground truth file')\n",
    "            get_groundtruth(world, camera, vehicle, frame_gt, K, K_b,timestamp_sec)\n",
    "            \n",
    "            frame = camera_data['image']\n",
    "            results = self.model(frame)\n",
    "            bbox_xyxy = []\n",
    "            conf_score = []\n",
    "            cls_id = []\n",
    "            outputs = []\n",
    "            for box in results:  \n",
    "                for row in box.boxes.data.tolist():\n",
    "                    x1, y1, x2, y2, conf, id = row    \n",
    "                    if int(id) in class_id:\n",
    "                        bbox_xyxy.append([int(x1), int(y1), int(x2), int(y2)])\n",
    "                        conf_score.append(conf)\n",
    "                        cls_id.append(int(id))\n",
    "                    else:\n",
    "                        continue                 \n",
    "                    outputs = self.deepsort.update(bbox_xyxy, conf_score, frame)\n",
    "\n",
    "                    \n",
    "\n",
    "                    for output , conf , id in zip(outputs , conf_score , cls_id):\n",
    "                        \n",
    "                        deepsort_writer.addObject('vehicle', timestamp_sec, output[0] ,output[1], output[2] - output[0] ,output[3] - output[1])\n",
    "                        \n",
    "                        deepsort_annotations.append({\n",
    "                                            \"dco\": True,\n",
    "                                            \"height\": output[3] - output[1],\n",
    "                                            \"width\": output[2] - output[0],\n",
    "                                            \"id\": \"vehicle\",  # Replace with actual class name\n",
    "                                            \"y\": output[1],\n",
    "                                            \"x\": output[0]\n",
    "                                                        })\n",
    "\n",
    "                    deepsort_final_annotations.append({\n",
    "                                \"timestamp\": timestamp_sec,\n",
    "                                \"num\": image.frame,\n",
    "                                \"class\": \"frame\",\n",
    "                                \"annotations\": deepsort_annotations\n",
    "                            })\n",
    "                    ds_output = {\n",
    "                                    \"frames\": deepsort_final_annotations,\n",
    "                                    \"class\": \"video\",\n",
    "                                    \"filename\": \"hypothese.json\"\n",
    "                                }\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    frame = np.array(frame)\n",
    "                    if len(outputs) > 0:\n",
    "                        for j, (output, conf) in enumerate(zip(outputs, conf_score)):\n",
    "                                frame = self.annotation(frame, output, conf, cls_id[j])\n",
    "\n",
    "                    with open ('hypothese.json' , 'w') as json_file:\n",
    "                            json.dump(ds_output , json_file)\n",
    "\n",
    "                        \n",
    "                    frame = cv2.UMat(frame)\n",
    "                    cv2.imshow('deepSORT', frame)\n",
    "                    cv2.imshow('ground truth', img)\n",
    "                    if self.save_vid:\n",
    "                        video_writer.write(frame)  \n",
    "                    if cv2.waitKey(1) == ord('q'):\n",
    "                        break\n",
    "\n",
    "                        \n",
    "        cv2.destroyAllWindows()\n",
    "        camera.stop()\n",
    "        camera.destroy()\n",
    "        vehicle.destroy()\n",
    "        clear()\n",
    "    def compute_color_for_labels(self , label):\n",
    "        color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n",
    "        return tuple(color)       \n",
    "    def annotation(self, frame, output, conf, cls_id):\n",
    "        x1, y1, x2, y2 = map(int,output[0:4])\n",
    "        id = int(output[4])\n",
    "        label = ''\n",
    "        if cls_id in class_name:\n",
    "            label = class_name[cls_id]  \n",
    "        frame = frame if isinstance(frame, np.ndarray) else np.array(frame)\n",
    "        color = self.compute_color_for_labels(id)\n",
    "        t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n",
    "        c_id = f'{label} {id}'\n",
    "        cv2.rectangle(frame, (x1, y1),(x2,y2), color, 1)\n",
    "        cv2.rectangle(frame, (x1, y1), (x1 + t_size[0] + 3, y1 + t_size[1] + 4), color, -1)\n",
    "        cv2.putText(frame, c_id, (x1, y1 + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [255, 255, 255], 2)\n",
    "        return frame    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    run = main()\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
